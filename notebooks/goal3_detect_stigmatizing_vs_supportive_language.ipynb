{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9baedb-edb4-44c1-89f4-168a73776dcc",
   "metadata": {},
   "source": [
    "# **Goal 3**. \n",
    "# Mental Health Stigma Classification in OSMI & Kaggle Surveys (2014–2023)\n",
    "\n",
    "This notebook performs a full pipeline for analyzing attitudes toward mental health in the tech industry across nine years of survey data (2014, 2016–2023). The workflow consists of:\n",
    "\n",
    "1. **Loading and harmonizing datasets** from Kaggle (2014, 2016–2019) and OSMI (2020–2023).\n",
    "2. **Extracting free-text answers** into a unified `\"text\"` column.\n",
    "3. **Manual annotation** of ~200 examples (supportive vs. stigmatizing language).\n",
    "4. **Semi-supervised labeling** of additional samples using Google Gemini.\n",
    "5. **Training a RoBERTa-based classifier** on manually + LLM-labeled data.\n",
    "6. **Evaluating** the model (accuracy, F1 score).\n",
    "7. **Applying the classifier to all years (2014–2023)** to detect supportive/stigmatizing language.\n",
    "8. **Trend analysis** to observe how attitudes change over time.\n",
    "\n",
    "The goal is to quantify stigma patterns and shifts in mental-health discourse within the tech workforce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615190f1-6bdb-4c2c-a4ad-af3f61d7e3a4",
   "metadata": {},
   "source": [
    "## Combine all free-text fields into a single column\n",
    "Combining all free-text responses into a single field allows a transformer model to capture the full semantic meaning of everything a respondent wrote, instead of treating each small text box separately. As a result, the model becomes more robust, more accurate, and better at recognizing subtle patterns related to mental health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7837c66a-de15-42d9-911b-37fb2c876796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa5517ae-e1e2-4c18-9a20-a9f942808dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_val(v):\n",
    "    bad_values = {\"-1\", \".\", \" \", \"\", \"nan\"}\n",
    "\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    v = str(v).strip()\n",
    "    return None if v in bad_values else v\n",
    "    \n",
    "\n",
    "def free_text(df):\n",
    "    df = df.replace(\"-1\", np.nan)\n",
    "    df = df.replace(-1, np.nan)\n",
    "\n",
    "    exclude_free_text = {\n",
    "    \"#\",\n",
    "    \"What country do you live in?\",\n",
    "    \"What country do you work in?\",\n",
    "    \"If you live in the United States, which state or territory do you live in?\",\n",
    "    \"If yes, what condition(s) have you been diagnosed with?\", # this would be data leakage\n",
    "    \"If maybe, what condition(s) do you believe you have?\", # this also\n",
    "    \"What US state or territory do you work in?\",\n",
    "    \"What is your age?\",\n",
    "    \"What is your gender?\",\n",
    "    \"SurveyID\",\n",
    "    \"UserID\",\n",
    "    \"Start Date (UTC)\",\n",
    "    \"Submit Date (UTC)\",\n",
    "    \"Network ID\",\n",
    "    }\n",
    "    UNIQUE_THRESHOLD = 50       # columns with > 50 unique values are likely free text\n",
    "    AVG_LENGTH_THRESHOLD = 20   # average length > 20 characters are likely free text\n",
    "\n",
    "    # add all free text into one array\n",
    "    free_text_cols = []\n",
    "    for col in df.columns:\n",
    "        if col in exclude_free_text:\n",
    "            continue\n",
    "            \n",
    "        num_unique = df[col].nunique()\n",
    "        avg_len = df[col].astype(str).apply(len).mean()\n",
    "        if num_unique > UNIQUE_THRESHOLD or avg_len > AVG_LENGTH_THRESHOLD:\n",
    "            free_text_cols.append(col)\n",
    "\n",
    "    print(\"Dataset free-text columns are: \")\n",
    "    for col in free_text_cols:\n",
    "        print(\"-\", col)\n",
    "        \n",
    "    # add all free text into one column & drop the others\n",
    "    df[\"all_text\"] = df[free_text_cols].apply(\n",
    "        lambda row: \" \".join(\n",
    "            [clean_val(v) for v in row if clean_val(v) is not None]),\n",
    "        axis=1)\n",
    "    \n",
    "    df[\"all_text\"] = df[\"all_text\"].replace(\"\", np.nan)\n",
    "    df.drop(columns=free_text_cols, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fae0c7-f5fb-419e-8418-7692253df492",
   "metadata": {},
   "source": [
    "## Combine free-text (2023 version)\n",
    "The 2023 dataset uses different schemas and column names. This function performs the same free-text merging logic while adapting to the updated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4292e6e7-22f2-4ed7-a8de-d1c6273bd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_text_2023(df):\n",
    "    df = df.replace(\"-1\", np.nan)\n",
    "    df = df.replace(-1, np.nan)\n",
    "\n",
    "    free_text_cols = [\n",
    "        \"Describe the conversation you had with your employer about your mental health, including their reactions and what actions were taken to address your mental health issue/questions.\",\n",
    "        \"Describe the conversation with coworkers you had about your mental health including their reactions.\",\n",
    "        \"Describe the conversation your coworker had with you about their mental health (please do not use names).\",\n",
    "        \"Describe the conversation you had with your previous employer about your mental health, including their reactions and actions taken to address your mental health issue/questions.\",\n",
    "        \"Describe the conversation you had with your previous coworkers about your mental health including their reactions.\",\n",
    "        \"Describe the conversation your coworker had with you about their mental health (please do not use names)..1\",\n",
    "        \"Describe the circumstances of the supportive or well handled response.\",\n",
    "        \"Describe the circumstances of the badly handled or unsupportive response.\",\n",
    "        \"Briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.\",\n",
    "        \"Would you have felt more comfortable talking to your previous employer about your physical health or your mental health?\",\n",
    "        \"Were you aware of the options for mental health care provided by your previous employers?\",\n",
    "        \"Would you have been willing to discuss your mental health with your direct supervisor(s)?\",\n",
    "        \"Would you have been willing to discuss your mental health with your coworkers at previous employers?\",\n",
    "        \"If there is anything else you would like to tell us that has not been covered by the survey questions, please use this space to do so.\",\n",
    "        \"Why or why not?\"\n",
    "    ]\n",
    "    \n",
    "    df[\"all_text\"] = df[free_text_cols].apply(\n",
    "        lambda row: \" \".join(\n",
    "            [clean_val(v) for v in row if clean_val(v) is not None]),\n",
    "        axis=1)\n",
    "    \n",
    "    df[\"all_text\"] = df[\"all_text\"].replace(\"\", np.nan)\n",
    "    df.drop(columns=free_text_cols, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe481f9-fe41-4eee-9828-6057b6d9b4c8",
   "metadata": {},
   "source": [
    "### Extracting Free-Text Fields from the Kaggle Historical Dataset\n",
    "\n",
    "The Kaggle dataset (2014–2019) contains over 100 columns, many of which are\n",
    "multiple-choice or demographic variables. However, for the purpose of\n",
    "language-based stigma classification we are only interested in **open-ended,\n",
    "free-text responses**.\n",
    "\n",
    "We therefore apply the `free_text()` function to automatically identify\n",
    "columns likely to contain narrative answers. The detection is based on:\n",
    "\n",
    "- high number of unique values,\n",
    "- long average string length,\n",
    "- exclusion of demographic or ID fields.\n",
    "\n",
    "All detected free-text columns are concatenated into a single column:\n",
    "`all_text`.\n",
    "\n",
    "This unified field allows us to build a consistent text corpus across all\n",
    "years.  \n",
    "\n",
    "After processing, the Kaggle dataset retains the same number of rows\n",
    "(4,218) but the number of columns decreases because all free-text responses\n",
    "are merged, and non-text free-text columns are removed.\n",
    "\n",
    "The preview shows that early survey years (2014–2015) contain no free-text\n",
    "responses for the first few entries, which is expected due to limited\n",
    "open-ended questions in early versions of the OSMI survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e1798b4-c522-4eaf-8433-cf35714472c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle shape before: (4218, 106)\n",
      "Dataset free-text columns are: \n",
      "- Any additional notes or comments\n",
      "- Briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.\n",
      "- Describe the circumstances of the badly handled or unsupportive response.\n",
      "- Describe the conversation with coworkers you had about your mental health including their reactions.\n",
      "- Describe the conversation you had with your employer about your mental health, including their reactions and what actions were taken to address your mental health issue/questions.\n",
      "- Describe the conversation you had with your previous coworkers about your mental health including their reactions.\n",
      "- Describe the conversation you had with your previous employer about your mental health, including their reactions and actions taken to address your mental health issue/questions.\n",
      "- Describe the conversation your coworker had with you about their mental health (please do not use names).\n",
      "- If there is anything else you would like to tell us that has not been covered by the survey questions, please use this space to do so.\n",
      "- Which of the following best describes your work position?\n",
      "- Would you have been willing to discuss your mental health with your direct supervisor(s)?\n",
      "Kaggle shape after free_text: (4218, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyID</th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SurveyID all_text\n",
       "0      2014      NaN\n",
       "1      2014      NaN\n",
       "2      2014      NaN\n",
       "3      2014      NaN\n",
       "4      2014      NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle = pd.read_csv(\"../data/raw/kaggle_uncleaned.csv\")\n",
    "print(\"Kaggle shape before:\", kaggle.shape)\n",
    "\n",
    "kaggle = free_text(kaggle)\n",
    "\n",
    "print(\"Kaggle shape after free_text:\", kaggle.shape)\n",
    "kaggle[[\"SurveyID\", \"all_text\"]].head()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09b9b4-47f6-4645-8c34-0a8faa9466b9",
   "metadata": {},
   "source": [
    "### Preparing Kaggle Free-Text Data for Labeling\n",
    "\n",
    "After extracting free-text fields into the `all_text` column, we create a\n",
    "standardized dataframe (`kaggle_text`) that matches the structure used for the\n",
    "OSMI datasets and for model training.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- `SurveyID` is renamed to `year` because the Kaggle dataset encodes the\n",
    "  survey year inside this column.\n",
    "- `all_text` is renamed to `text` so that all datasets share a unified text\n",
    "  field.\n",
    "- A placeholder `label` column is added and filled with `NaN`, since the\n",
    "  Kaggle historical dataset does not include stigma labels.\n",
    "  These entries will later be ignored during model training unless we choose to\n",
    "  generate pseudo-labels.\n",
    "\n",
    "The resulting dataset contains:\n",
    "- **4,218 rows**, matching the original Kaggle sample size.\n",
    "- Columns: `year`, `text`, and `label`.\n",
    "\n",
    "The first few rows show that many early-year responses contain no free text,\n",
    "which is expected for the 2014–2015 survey versions that had fewer\n",
    "open-ended questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1579cfa-c83f-49c7-b487-d8aef0787d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4218, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year text  label\n",
       "0  2014  NaN    NaN\n",
       "1  2014  NaN    NaN\n",
       "2  2014  NaN    NaN\n",
       "3  2014  NaN    NaN\n",
       "4  2014  NaN    NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_text = kaggle[[\"SurveyID\", \"all_text\"]].rename(\n",
    "    columns={\"SurveyID\": \"year\", \"all_text\": \"text\"}\n",
    ")\n",
    "kaggle_text[\"label\"] = np.nan\n",
    "print(kaggle_text.shape)\n",
    "kaggle_text[\"year\"].value_counts().sort_index()\n",
    "kaggle_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e969d-2df6-4fb7-9b8a-4a4a453ee89d",
   "metadata": {},
   "source": [
    "### Processing OSMI Survey Data (2020–2023)\n",
    "\n",
    "The OSMI mental-health surveys from 2020–2023 contain several open-ended\n",
    "questions where respondents describe their experiences with mental health,\n",
    "workplace attitudes, and conversations with employers or coworkers.\n",
    "\n",
    "However, the survey structure **changes from year to year**, most notably in 2023,\n",
    "which requires a separate text-extraction function.  \n",
    "To standardize these datasets for later modeling, we perform the following steps\n",
    "for each year:\n",
    "\n",
    "1. **Load the raw CSV file** and display its original shape.\n",
    "2. **Extract free-text answers**:\n",
    "   - For 2023, call `free_text_2023()` because column names differ.\n",
    "   - For 2020–2022, use the general `free_text()` function.\n",
    "3. **Rename the combined text column** (`all_text`) to a unified field (`text`).\n",
    "4. **Add metadata columns**:\n",
    "   - `year` — the survey year\n",
    "   - `label` — placeholder `NaN` values, because we will label these\n",
    "     rows later using manual annotation or model-assisted labeling.\n",
    "5. **Store the processed dataframe** in a list for later concatenation.\n",
    "\n",
    "This loop produces a consistent text dataset across all OSMI survey years,\n",
    "making the subsequent steps—merging, labeling, and training—the same for\n",
    "every sample regardless of its original format.\n",
    "\n",
    "Example rows are displayed for quick inspection to verify that free-text\n",
    "aggregation worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b05b4a4-cb3e-4a4a-ad05-98f850e1aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing OSMI 2020 ===\n",
      "Raw shape: (180, 120)\n",
      "Dataset free-text columns are: \n",
      "- Describe the conversation you had with your employer about your mental health, including their reactions and what actions were taken to address your mental health issue/questions.\n",
      "- Describe the conversation with coworkers you had about your mental health including their reactions.\n",
      "- Describe the conversation your coworker had with you about their mental health (please do not use names).\n",
      "- Would you have been willing to discuss your mental health with your direct supervisor(s)?\n",
      "- Would you have been willing to discuss your mental health with your coworkers at previous employers?\n",
      "- Describe the conversation you had with your previous coworkers about your mental health including their reactions.\n",
      "- Why or why not?\n",
      "- Why or why not?.1\n",
      "- Describe the circumstances of the badly handled or unsupportive response.\n",
      "- Briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.\n",
      "- If there is anything else you would like to tell us that has not been covered by the survey questions, please use this space to do so.\n",
      "After free_text: (180, 110)\n",
      "OSMI 2020 example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, none of my previous supervisors At some of...</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes, all of my previous supervisors Yes, at al...</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  label\n",
       "0  No, none of my previous supervisors At some of...  2020    NaN\n",
       "1  Yes, all of my previous supervisors Yes, at al...  2020    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing OSMI 2021 ===\n",
      "Raw shape: (131, 124)\n",
      "Dataset free-text columns are: \n",
      "- Describe the conversation you had with your employer about your mental health, including their reactions and what actions were taken to address your mental health issue/questions.\n",
      "- Describe the conversation with coworkers you had about your mental health including their reactions.\n",
      "- Describe the conversation your coworker had with you about their mental health (please do not use names).\n",
      "- Would you have been willing to discuss your mental health with your direct supervisor(s)?\n",
      "- Describe the conversation you had with your previous employer about your mental health, including their reactions and actions taken to address your mental health issue/questions.\n",
      "- Would you have been willing to discuss your mental health with your coworkers at previous employers?\n",
      "- Describe the conversation you had with your previous coworkers about your mental health including their reactions.\n",
      "- Why or why not?\n",
      "- Why or why not?.1\n",
      "- Briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.\n",
      "- If there is anything else you would like to tell us that has not been covered by the survey questions, please use this space to do so.\n",
      "After free_text: (131, 114)\n",
      "OSMI 2021 example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some of my previous supervisors Yes, at all of...</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No, none of my previous supervisors No, at non...</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  label\n",
       "0  Some of my previous supervisors Yes, at all of...  2021    NaN\n",
       "1  No, none of my previous supervisors No, at non...  2021    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing OSMI 2022 ===\n",
      "Raw shape: (164, 126)\n",
      "Dataset free-text columns are: \n",
      "- Describe the conversation you had with your employer about your mental health, including their reactions and what actions were taken to address your mental health issue/questions.\n",
      "- Describe the conversation with coworkers you had about your mental health including their reactions.\n",
      "- Describe the conversation your coworker had with you about their mental health (please do not use names).\n",
      "- Would you have been willing to discuss your mental health with your direct supervisor(s)?\n",
      "- Would you have been willing to discuss your mental health with your coworkers at previous employers?\n",
      "- Why or why not?\n",
      "- Why or why not?.1\n",
      "- Briefly describe what you think the industry as a whole and/or employers could do to improve mental health support for employees.\n",
      "After free_text: (164, 119)\n",
      "OSMI 2022 example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, none of my previous supervisors No, at non...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had a burnout (another after 10 years) due t...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  label\n",
       "0  No, none of my previous supervisors No, at non...  2022    NaN\n",
       "1  I had a burnout (another after 10 years) due t...  2022    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing OSMI 2023 ===\n",
      "Raw shape: (6, 126)\n",
      "After free_text: (6, 112)\n",
      "OSMI 2023 example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They appeared to be ok with my weekly therapy ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's hard. I'm not sure how we can strike a ba...</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  label\n",
       "0  They appeared to be ok with my weekly therapy ...  2023    NaN\n",
       "1  It's hard. I'm not sure how we can strike a ba...  2023    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths_osmi = {\n",
    "    2020: \"../data/raw/osmi_mental_health_2020.csv\",\n",
    "    2021: \"../data/raw/osmi_mental_health_2021.csv\",\n",
    "    2022: \"../data/raw/osmi_mental_health_2022.csv\",\n",
    "    2023: \"../data/raw/osmi_mental_health_2023.csv\",\n",
    "}\n",
    "\n",
    "osmi_text_dfs = []\n",
    "for year, path in paths_osmi.items():\n",
    "    print(f\"\\n=== Processing OSMI {year} ===\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Raw shape:\", df.shape)\n",
    "    if year == 2023:\n",
    "        df = free_text_2023(df)\n",
    "    else:\n",
    "        df = free_text(df)\n",
    "    print(\"After free_text:\", df.shape)\n",
    "\n",
    "    tmp = df[[\"all_text\"]].rename(columns={\"all_text\": \"text\"})\n",
    "    tmp[\"year\"] = year\n",
    "    tmp[\"label\"] = np.nan\n",
    "\n",
    "    osmi_text_dfs.append(tmp)\n",
    "\n",
    "    print(f\"OSMI {year} example rows:\")\n",
    "    display(tmp.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedb199-1f2c-4530-aa09-5c318a092065",
   "metadata": {},
   "source": [
    "### Combine Kaggle and OSMI Free-Text Responses into a Unified Dataset\n",
    "\n",
    "At this point, we have extracted all free-text fields from the Kaggle dataset\n",
    "(2014–2019) and from the OSMI datasets (2020–2023).  \n",
    "Each yearly dataset now shares a consistent structure with three columns:\n",
    "\n",
    "- **year** — the survey year  \n",
    "- **text** — aggregated free-text answers from that respondent  \n",
    "- **label** — placeholder values (`NaN`), to be assigned later during manual or model-assisted annotation  \n",
    "\n",
    "To build a single corpus for labeling and model training, the datasets are\n",
    "vertically concatenated:\n",
    "\n",
    "1. **Merge Kaggle + all OSMI dataframes** into one large dataframe.\n",
    "2. **Normalize empty strings**:  \n",
    "   Replace `\"\"` and `\"nan\"` (string artifacts) with actual `NaN` values.\n",
    "3. **Remove rows without text**, since they provide no usable signal for\n",
    "   classification.\n",
    "4. **Reset the index** to produce a clean, continuous row numbering.\n",
    "\n",
    "After these steps, `full_text_df` contains the complete set of free-text mental-health\n",
    "responses from 2014–2023, ready for downstream processing (manual labeling,\n",
    "semi-supervised labeling, and model training).\n",
    "\n",
    "A preview of the final dataset is printed along with counts per survey year to\n",
    "verify correct merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a5027ef-a4de-492d-8386-3554d836f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL dataset shape: (3506, 3)\n",
      "year\n",
      "2014     163\n",
      "2016    1433\n",
      "2017     723\n",
      "2018     400\n",
      "2019     335\n",
      "2020     174\n",
      "2021     116\n",
      "2022     156\n",
      "2023       6\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>I'm not on my company's health insurance, whic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>I have chronic, low-level neurological issues ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>My company does provide healthcare, but not to...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>Relatively new job. Ask again later</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Sometimes I think  about using drugs for my me...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               text  label\n",
       "0  2014  I'm not on my company's health insurance, whic...    NaN\n",
       "1  2014  I have chronic, low-level neurological issues ...    NaN\n",
       "2  2014  My company does provide healthcare, but not to...    NaN\n",
       "3  2014                Relatively new job. Ask again later    NaN\n",
       "4  2014  Sometimes I think  about using drugs for my me...    NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_df = pd.concat(\n",
    "    [kaggle_text] + osmi_text_dfs,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "full_text_df[\"text\"] = full_text_df[\"text\"].replace([\"\", \"nan\"], np.nan)\n",
    "full_text_df = full_text_df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"FULL dataset shape:\", full_text_df.shape)\n",
    "print(full_text_df[\"year\"].value_counts().sort_index())\n",
    "full_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e646cb-dd0d-48be-8aae-37b79aecaaee",
   "metadata": {},
   "source": [
    "### Save the Unified Dataset for Reproducibility\n",
    "\n",
    "After combining and cleaning all free-text responses (2014–2023), we store the\n",
    "complete dataset as a CSV file.  \n",
    "This snapshot serves as the canonical version of the unlabeled corpus used for\n",
    "manual annotation, semi-supervised labeling, and downstream model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "379a0850-0d55-4e52-bcf7-1890a6bf1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_df.to_csv(\"../data/processed/full_text_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37a371-a478-42c8-b1b3-cfffe9ca2fac",
   "metadata": {},
   "source": [
    "### Save a 200-row sample for manual annotation\n",
    "\n",
    "To create a high-quality ground-truth subset for model evaluation, we extract a\n",
    "random sample of **200 free-text responses** from the unified dataset.  \n",
    "These entries will later be manually labeled (0 = stigmatizing, 1 = supportive,\n",
    "2 = unclear). The annotated subset will serve as:\n",
    "\n",
    "- a gold-standard reference for validating model-generated labels,\n",
    "- an anchor for calibration of semi-supervised labeling,\n",
    "- and a small but reliable training component for downstream models.\n",
    "\n",
    "We fix `random_state=42` to ensure reproducibility.  \n",
    "The sample is then exported to a CSV file for external annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "565bdfaf-c62f-4d6e-8847-19e272500cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>If it might affect my chance at employment. It...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>One-person shop</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Become more acceptable of it, such as explicit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>I've mentioned therapy and anxiety and possibl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Other Some of my previous employers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               text  label\n",
       "0  2021  If it might affect my chance at employment. It...    NaN\n",
       "1  2016                                    One-person shop    NaN\n",
       "2  2017  Become more acceptable of it, such as explicit...    NaN\n",
       "3  2022  I've mentioned therapy and anxiety and possibl...    NaN\n",
       "4  2016                Other Some of my previous employers    NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_n = 200\n",
    "manual_df = full_text_df.sample(manual_n, random_state=42).reset_index(drop=True)\n",
    "\n",
    "manual_df.to_csv(\"../data/processed/manual_annotation_sample.csv\", index=False)\n",
    "manual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08510b5b-9c74-4421-a8db-c69f3f1f0ebe",
   "metadata": {},
   "source": [
    "### Load the manually annotated sample\n",
    "\n",
    "After completing the manual labeling process externally, we import the filled-in\n",
    "annotation file back into the workflow. This dataset now contains human-verified\n",
    "labels for each of the 200 sampled responses.\n",
    "\n",
    "\n",
    "We load the file, inspect its shape, and verify the distribution of the assigned labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f803bb84-3635-4b30-bd71-ea7af8e8dbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>If it might affect my chance at employment. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>One-person shop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Become more acceptable of it, such as explicit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>I've mentioned therapy and anxiety and possibl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Other Some of my previous employers</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               text  label\n",
       "0  2021  If it might affect my chance at employment. It...      0\n",
       "1  2016                                    One-person shop      2\n",
       "2  2017  Become more acceptable of it, such as explicit...      1\n",
       "3  2022  I've mentioned therapy and anxiety and possibl...      1\n",
       "4  2016                Other Some of my previous employers      2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = pd.read_csv(\"../data/processed/manual_annotation_sample_filled.csv\")\n",
    "\n",
    "print(manual_df.shape)\n",
    "manual_df['label'].value_counts()\n",
    "manual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ffa3c-1f72-42b9-b6df-b9e5d83ec023",
   "metadata": {},
   "source": [
    "### Remove ambiguous labels (label = 2)\n",
    "\n",
    "During manual annotation, some responses were assigned the label **2**, meaning\n",
    "the sentiment toward mental health could not be clearly determined.  \n",
    "Because the predictive task is binary (supportive = 1, stigmatizing = 0), these\n",
    "ambiguous cases are excluded from the supervised training set.\n",
    "\n",
    "In this step, we filter the manually annotated DataFrame to keep only rows with\n",
    "labels **0 or 1**, reset the index, and verify the resulting class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72fdaa3d-ea10-4716-85e3-e0ad14fe5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    42\n",
       "0    37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_clean = manual_df[manual_df[\"label\"].isin([0,1])].copy()\n",
    "manual_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(manual_clean.shape)\n",
    "manual_clean['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6adc101-2dca-490d-86ce-f9fbab58f1a4",
   "metadata": {},
   "source": [
    "### Prepare a Gemini labeling subset by removing manually annotated rows\n",
    "\n",
    "Before sending additional data to Gemini for automated labeling, we must ensure\n",
    "that **none of the manually annotated samples are included again**.  \n",
    "To do this, we:\n",
    "\n",
    "1. Assign a simple sequential `id` column to the manually annotated dataset.\n",
    "2. Copy the full dataset and ensure it also has a matching `id` column.\n",
    "3. Remove all rows whose `id` appears in the manually annotated subset.\n",
    "4. From the remaining unlabeled data, sample 800 rows to create the dataset that\n",
    "   will be labeled by Gemini.\n",
    "\n",
    "This guarantees that manually labeled examples and Gemini-labeled examples are\n",
    "disjoint, preventing label leakage and preserving a clean training workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "418ccee6-accd-48b0-aaa6-41def01c98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_clean[\"id\"] = range(len(manual_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f3ec54d-839a-43b5-9ef3-27d2f92c291e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>657</td>\n",
       "      <td>2016</td>\n",
       "      <td>Back-end Developer Some of my previous employers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1940</td>\n",
       "      <td>2017</td>\n",
       "      <td>Educate employees about mental health and what...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643</td>\n",
       "      <td>2016</td>\n",
       "      <td>Front-end Developer No, at none of my previous...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2727</td>\n",
       "      <td>2019</td>\n",
       "      <td>Provide support and educate from the top down ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2799</td>\n",
       "      <td>2019</td>\n",
       "      <td>make it less taboo break-up related, got suppo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                               text  label\n",
       "0   657  2016   Back-end Developer Some of my previous employers    NaN\n",
       "1  1940  2017  Educate employees about mental health and what...    NaN\n",
       "2   643  2016  Front-end Developer No, at none of my previous...    NaN\n",
       "3  2727  2019  Provide support and educate from the top down ...    NaN\n",
       "4  2799  2019  make it less taboo break-up related, got suppo...    NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = full_text_df.copy()\n",
    "\n",
    "if \"id\" not in full_df.columns:\n",
    "    full_df = full_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "manual_ids = manual_clean[\"id\"].tolist()\n",
    "\n",
    "remaining_df = full_df[~full_df[\"id\"].isin(manual_ids)].reset_index(drop=True)\n",
    "\n",
    "gemini_df = remaining_df.sample(800, random_state=42).reset_index(drop=True)\n",
    "\n",
    "gemini_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d2eee-295e-4682-a3ab-608e42439e59",
   "metadata": {},
   "source": [
    "### Install the Google GenAI client library\n",
    "\n",
    "To access the Gemini API from Python, we first install the official\n",
    "`google-genai` package.  \n",
    "This lightweight client provides a simple interface for sending text\n",
    "generation and classification requests to Google's Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "496e9180-ad7d-41f3-b5e7-04a56f433aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Downloading google_genai-1.53.0-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.43.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (2.12.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (9.0.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.7)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.8)\n",
      "Downloading google_genai-1.53.0-py3-none-any.whl (262 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: anyio, google-genai\n",
      "\u001b[2K  Attempting uninstall: anyio\n",
      "\u001b[2K    Found existing installation: anyio 4.7.0\n",
      "\u001b[2K    Uninstalling anyio-4.7.0:\n",
      "\u001b[2K      Successfully uninstalled anyio-4.7.0\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [google-genai]0m \u001b[32m1/2\u001b[0m [google-genai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anyio-4.12.0 google-genai-1.53.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce6114-cc82-4fda-ae0d-0a1ed6def883",
   "metadata": {},
   "source": [
    "## Automatic Labeling Using Google Gemini\n",
    "\n",
    "To expand the labeled dataset, we generate labels for 800 previously unlabeled free-text survey responses using the Gemini 2.0 Flash model. These labels are not treated as ground truth; instead, they serve as an additional signal that can later be reviewed, filtered, or refined before inclusion in the final training set.\n",
    "\n",
    "### Classification task\n",
    "\n",
    "Each text sample is classified into one of three categories:\n",
    "\n",
    "| Label | Description |\n",
    "|-------|-------------|\n",
    "| **0 – Stigmatizing** | Negative stereotypes, judgement, dismissal of mental-health struggles, rejection or discomfort discussing mental health. |\n",
    "| **1 – Supportive** | Empathy, understanding, openness, or neutral/personal descriptions of mental-health experiences. Personal suffering is considered supportive rather than unclear. |\n",
    "| **2 – Unclear / No attitude** | Text contains no interpretable sentiment related to mental health (e.g., “N/A”, “none”, “don’t remember”), or is irrelevant to the task. |\n",
    "\n",
    "### Prompt design\n",
    "\n",
    "A structured prompt is used to enforce consistent labeling. The prompt includes:\n",
    "\n",
    "- Definitions of all three classes  \n",
    "- Decision rules (e.g., default to 1 for neutral personal descriptions; default to 0 for avoidance or rejection)  \n",
    "- Examples illustrating both supportive and stigmatizing responses  \n",
    "- An instruction to output only a single number: 0, 1, or 2\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. Copy the sampled dataset (`gemini_df`) for labeling.  \n",
    "2. For each row, append the text to the prompt and send it to the Gemini API.  \n",
    "3. Parse the model’s response and map it to label 0, 1, or 2.  \n",
    "4. Add a short delay between requests to avoid rate-limit issues.  \n",
    "5. Save the resulting labeled dataset to `../data/processed/gemini_labeled.csv`.\n",
    "\n",
    "This process yields a labeled dataset, which can be combined with manually annotated data and further cleaned before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7e184db-ed4a-4e90-84d3-370393670b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    438\n",
       "1    293\n",
       "0     69\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# API key\n",
    "client = genai.Client(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "df_gem = gemini_df.copy()\n",
    "\n",
    "labels = []\n",
    "\n",
    "prompt_base = \"\"\"\n",
    "You are classifying mental-health related text.\n",
    "\n",
    "Your ONLY task is to decide whether the speaker's attitude toward mental health\n",
    "is SUPPORTIVE (1), STIGMATIZING (0), or UNCLEAR (2).\n",
    "\n",
    "DEFINITIONS:\n",
    "\n",
    "0 = STIGMATIZING  \n",
    "- Shows judgment, blame, dismissal, or negative stereotypes.\n",
    "- Minimizes or invalidates mental-health struggles.\n",
    "- Expresses rejection, avoidance, discomfort, or unwillingness to discuss.\n",
    "- Examples:\n",
    "  - \"People should just toughen up.\"\n",
    "  - \"I don't want to work with someone with mental health issues.\"\n",
    "  - \"None of my supervisors would ever tolerate that.\"\n",
    "\n",
    "1 = SUPPORTIVE\n",
    "- Shows understanding, empathy, personal sharing, or openness.\n",
    "- Describes mental-health conversations positively.\n",
    "- Indicates willingness to talk, help, or support.\n",
    "- Neutral descriptions of personal experience COUNT AS SUPPORTIVE unless negative toward others.\n",
    "- Examples:\n",
    "  - \"We talked openly about burnout.\"\n",
    "  - \"My supervisor was understanding.\"\n",
    "  - \"I struggled with anxiety but got help.\"\n",
    "\n",
    "2 = UNCLEAR / NO ATTITUDE  \n",
    "Use ONLY when:\n",
    "- The text contains *zero* mental-health sentiment.\n",
    "- Answer is literally something like: \"N/A\", \"None\", \"Don't remember\", \"-\", \"No info\".\n",
    "- Purely factual lists with no attitude.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "\n",
    "- If the text contains ANY emotional tone about mental health, choose 0 or 1.\n",
    "- If the text describes personal suffering or neutral recounting, choose 1 (NOT 2).\n",
    "- If the text shows hesitation, avoidance, rejection, or discomfort, choose 0.\n",
    "\n",
    "Now classify the following text.\n",
    "\n",
    "\n",
    "Answer only with:  \n",
    "0 (stigmatizing)  \n",
    "1 (supportive)  \n",
    "2 (unclear)\n",
    "\"\"\"\n",
    "\n",
    "for text in df_gem[\"text\"]:\n",
    "    prompt = prompt_base + f'\\n\\nTEXT:\\n\"{text}\"\\n\\nLabel:'\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",  \n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    ans = response.text.strip()\n",
    "\n",
    "    if ans.startswith(\"1\"):\n",
    "        labels.append(1)\n",
    "    elif ans.startswith(\"0\"):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(2)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "df_gem[\"label\"] = labels\n",
    "df_gem.to_csv(\"../data/processed/gemini_labeled.csv\", index=False)\n",
    "df_gem[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e92c1-7d53-4e57-b0a1-81023888018e",
   "metadata": {},
   "source": [
    "### Manual Review and Correction of Gemini-Generated Labels\n",
    "\n",
    "After generating weak labels with Gemini, the full labeled file was manually inspected.  \n",
    "During this review, some samples originally assigned the label `2` (unclear/no-attitude) were corrected to either:\n",
    "\n",
    "- **0 — stigmatizing**, or  \n",
    "- **1 — supportive**,  \n",
    "\n",
    "because the model had been overly conservative and marked texts as unclear even when sentiment toward mental health was present.\n",
    "\n",
    "The manually edited file (`gemini_labeled.csv`) is now reloaded and serves as the final version of the gemini-labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67147eb5-863a-4c22-a5dc-f4bb8fb32e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_label_checked_df = pd.read_csv(\"../data/processed/gemini_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e9ff5ff-883e-4891-b087-c98afeb82bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    433\n",
       "1    297\n",
       "0     70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_label_checked_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe1e16-b3bb-4bca-bc48-f9f5ae3fcfb2",
   "metadata": {},
   "source": [
    "### Iteratively Expanding the Training Set: Adding More Stigmatizing Examples (Label 0)\n",
    "\n",
    "Even after the first round of manual annotation and weak labeling, the dataset remained imbalanced:  \n",
    "supportive examples were far more common than stigmatizing ones.  \n",
    "Because a classifier cannot learn minority classes well without sufficient examples, we performed an **iterative enrichment step** to collect additional candidate rows likely to contain stigmatizing sentiment.\n",
    "\n",
    "This code identifies rows that:\n",
    "\n",
    "1. **Have not been labeled yet** (not present in either manually annotated data or Gemini-checked data).\n",
    "2. **Belong to the remaining pool** of unlabeled survey responses.\n",
    "3. Are selected via sampling (`N = 200`) for the next manual annotation round.\n",
    "\n",
    "We keep only the essential fields (`id`, `year`, `text`) and export the sample as  \n",
    "`to_label_next_round.csv`, which will be filled in manually with label values.\n",
    "This iterative sampling strategy allows us to:\n",
    "- systematically expand the dataset,\n",
    "- target underrepresented classes (especially label 0),\n",
    "- and improve model performance through better class balance.\n",
    "\n",
    "After manual annotation, the newly labeled rows will be merged back into the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a0f7330-7fa8-4ccd-898e-3fe59b5e5c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already labeled rows: 879\n",
      "Rows to be labeled: (2627, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for id column, if not, add:\n",
    "if \"id\" not in full_text_df.columns:\n",
    "    full_text_df = full_text_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "\n",
    "# All already labeled ids (manual + gemini-labeled)\n",
    "labeled_ids = pd.concat([\n",
    "    manual_clean[[\"id\"]],\n",
    "    gemini_label_checked_df[[\"id\"]]\n",
    "], ignore_index=True)[\"id\"].unique()\n",
    "\n",
    "print(\"Already labeled rows:\", len(labeled_ids))\n",
    "\n",
    "# Those that have not been labeled yet\n",
    "remaining = full_text_df[~full_text_df[\"id\"].isin(labeled_ids)].copy()\n",
    "print(\"Rows to be labeled:\", remaining.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c7285522-97f5-4b2a-83e7-65bb2f020091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>390</td>\n",
       "      <td>2016</td>\n",
       "      <td>Supervisor/Team Lead No, at none of my previou...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>520</td>\n",
       "      <td>2016</td>\n",
       "      <td>Supervisor/Team Lead | Back-end Developer No, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1328</td>\n",
       "      <td>2016</td>\n",
       "      <td>Back-end Developer | Front-end Developer No, a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>3319</td>\n",
       "      <td>2021</td>\n",
       "      <td>My boss was pretty ambivalent. Seemed uncomfor...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>1968</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stop putting an emphasis on the glory of overw...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  year                                               text label\n",
       "390    390  2016  Supervisor/Team Lead No, at none of my previou...      \n",
       "520    520  2016  Supervisor/Team Lead | Back-end Developer No, ...      \n",
       "1328  1328  2016  Back-end Developer | Front-end Developer No, a...      \n",
       "3319  3319  2021  My boss was pretty ambivalent. Seemed uncomfor...      \n",
       "1968  1968  2017  Stop putting an emphasis on the glory of overw...      "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 200  # Choose how many rows to be labeled next\n",
    "\n",
    "to_label_next = remaining.sample(N, random_state=42).copy()\n",
    "\n",
    "# Keep only the rows that matter for labeling\n",
    "to_label_next = to_label_next[[\"id\", \"year\", \"text\"]]\n",
    "to_label_next[\"label\"] = \"\"\n",
    "to_label_next.to_csv(\"../data/processed/to_label_next_round.csv\", index=False)\n",
    "to_label_next.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1bf8f3-dcaf-4182-8544-f0936fb2803c",
   "metadata": {},
   "source": [
    "### Load the Second Round of Manual Annotations\n",
    "\n",
    "After sampling additional unlabeled rows in the previous step and manually assigning\n",
    "labels to them (with a focus on enriching the minority class, label `0`), we now\n",
    "load the completed annotation file back into the workflow.\n",
    "\n",
    "This file (`manual_round2.csv`) contains:\n",
    "- the same `id`, `year`, and `text` fields as the sampled rows,\n",
    "- a newly added `label` column filled in by the annotator.\n",
    "\n",
    "By loading this dataframe, we can:\n",
    "1. verify the distribution of newly assigned labels,\n",
    "2. merge these results into the existing manually labeled dataset,\n",
    "3. improve class balance before retraining the model.\n",
    "\n",
    "This step is part of the iterative annotation cycle that progressively\n",
    "strengthens the dataset and enhances classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "15b51aad-ec90-4956-bd31-48aed3ab3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_round2_df = pd.read_csv(\"../data/processed/manual_round2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ed93a-52fc-40e2-bf79-3d6826967852",
   "metadata": {},
   "source": [
    "### Build the Final Training Dataset\n",
    "\n",
    "To train the classifier, we combine all high-quality labelled data collected\n",
    "through the multi-stage annotation process:\n",
    "\n",
    "1. **`manual_clean`** — the initial manually annotated sample  \n",
    "   (only labels `0` = stigmatizing and `1` = supportive retained)\n",
    "\n",
    "2. **`gemini_label_checked_df`** — machine-generated labels from Gemini,\n",
    "   followed by human correction and removal of unclear cases (`label = 2`)\n",
    "\n",
    "3. **`manual_round2_df`** — an additional batch of manually labelled rows,\n",
    "   intentionally sampled to increase the representation of the minority class (`0`)\n",
    "\n",
    "Before concatenation, each source dataset is filtered to keep only\n",
    "valid supervised labels (`0` or `1`).  \n",
    "After combining, the resulting training dataset contains:\n",
    "\n",
    "- **339 supportive examples (`label = 1`)**\n",
    "- **130 stigmatizing examples (`label = 0`)**\n",
    "\n",
    "This distribution reflects a significantly improved class balance compared to\n",
    "earlier iterations and provides a stronger foundation for fine-tuning the\n",
    "RoBERTa-based classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b92ad235-8a23-430e-b59a-f292e041b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([\n",
    "    manual_clean[manual_clean[\"label\"].isin([0,1])],\n",
    "    gemini_label_checked_df[gemini_label_checked_df[\"label\"].isin([0,1])],\n",
    "    manual_round2_df[manual_round2_df[\"label\"].isin([0,1])]\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d956426f-b37c-4484-a9c6-47dd1af30045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    339\n",
       "0.0    130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3310edf8-9d54-4f1e-b186-bb39217f53e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'text', 'label', 'id'], dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54c122-b2f4-41c4-8f94-bfe6f5d92f7e",
   "metadata": {},
   "source": [
    "### 1) Train/Validation/Test Split\n",
    "\n",
    "To evaluate the RoBERTa classifier reliably, the labelled dataset is divided\n",
    "into three subsets using a two-step stratified split:\n",
    "\n",
    "- **Test set (20%)**  \n",
    "  Held out completely for final unbiased evaluation.\n",
    "\n",
    "- **Validation set (16%)**  \n",
    "  Obtained by splitting 20% of the remaining 80%.  \n",
    "  Used for model selection, early stopping, and monitoring overfitting.\n",
    "\n",
    "- **Training set (64%)**  \n",
    "  Used for optimizing model weights during fine-tuning.\n",
    "\n",
    "Stratification ensures that the class distribution (supportive vs.\n",
    "stigmatizing) remains balanced across all splits, which is important due to the\n",
    "dataset’s moderate label imbalance.\n",
    "\n",
    "The random seed (`random_state=42`) is used to guarantee reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "450721a4-3a03-40e1-9516-3aa3d9914ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2462c7f-2fae-4214-b7b8-94bddec3c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (300, 4)\n",
      "Val: (75, 4)\n",
      "Test: (94, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df_split, test_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42,\n",
    "    stratify = train_df[\"label\"]\n",
    ")\n",
    "\n",
    "train_df_final, val_df = train_test_split(\n",
    "    train_df_split,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42,\n",
    "    stratify=train_df_split[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df_final.shape)\n",
    "print(\"Val:\", val_df.shape)\n",
    "print(\"Test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04f318-06e2-4e55-a8ec-e5a99c7df9f2",
   "metadata": {},
   "source": [
    "---\n",
    "### 2) HuggingFace Datasets: Tokenizer + PyTorch Dataset\n",
    "\n",
    "To fine-tune RoBERTa, we first need to install PyTorch, which provides the\n",
    "tensor backend and dataloader utilities used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d31179c7-0104-4d38-8923-07c428c2ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb12cb1-d7ce-4e5e-8108-6f340c42caa5",
   "metadata": {},
   "source": [
    "### Custom PyTorch Dataset\n",
    "\n",
    "HuggingFace’s `Trainer` expects training data to be provided as a PyTorch\n",
    "`Dataset` that returns tokenized inputs and labels for each sample.  \n",
    "To enable this, we define a custom `TextClassificationDataset` class.\n",
    "\n",
    "This dataset performs the following steps:\n",
    "\n",
    "1. **Stores text and labels** from the pandas DataFrame.\n",
    "2. **Tokenizes each text sample** using the same RoBERTa tokenizer that will be\n",
    "   used during training.\n",
    "3. Applies RoBERTa-compatible preprocessing:\n",
    "   - truncation to a fixed maximum length,\n",
    "   - padding to `max_length`,\n",
    "   - returning PyTorch tensors (`return_tensors=\"pt\"`).\n",
    "4. Returns a dictionary with the exact keys expected by the model:\n",
    "   - `\"input_ids\"`\n",
    "   - `\"attention_mask\"`\n",
    "   - `\"labels\"`\n",
    "\n",
    "This structure allows seamless integration with the HuggingFace `Trainer` API\n",
    "and ensures that batching, padding, and device placement are handled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5df1d247-56cb-4086-bae0-24a66c02e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.texts = df[\"text\"].astype(str).tolist()\n",
    "        self.labels = df[\"label\"].astype(int).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce251c8-a878-4d94-ac80-bd07678c5979",
   "metadata": {},
   "source": [
    "### 4) Load RoBERTa Tokenizer and Build Training Datasets\n",
    "\n",
    "To prepare our text data for RoBERTa, we load the **`roberta-base`** tokenizer\n",
    "from HuggingFace. The tokenizer converts raw text into token IDs and attention\n",
    "masks that the model can process.\n",
    "\n",
    "We then wrap each split (train, validation, test) using our custom\n",
    "`TextClassificationDataset` class defined earlier.  \n",
    "This ensures that:\n",
    "\n",
    "- each text sample is tokenized consistently with RoBERTa vocabulary,\n",
    "- sequences are padded/truncated to a fixed maximum length,\n",
    "- labels are returned as PyTorch tensors,\n",
    "- the HuggingFace `Trainer` API can directly use these datasets.\n",
    "\n",
    "This step creates fully model-ready datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b1e523ff-e280-47a9-8ef5-fc7f5c752d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.46.0 in /opt/anaconda3/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.24.6 in /opt/anaconda3/lib/python3.13/site-packages (0.36.0)\n",
      "Collecting huggingface_hub>=0.24.6\n",
      "  Using cached huggingface_hub-1.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers>=4.46.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.24.6) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.24.6) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.24.6) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers>=4.46.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers>=4.46.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers>=4.46.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers>=4.46.0) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"transformers>=4.46.0\" \"huggingface_hub>=0.24.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d23fd0ef-4201-4168-a0d0-b177477bd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "52e1fd85-51c6-4d09-80a7-96c0050bf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_df_final, tokenizer)\n",
    "val_dataset = TextClassificationDataset(val_df, tokenizer)\n",
    "test_dataset = TextClassificationDataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3094213-2dcc-49a8-8a3f-9cac5459b910",
   "metadata": {},
   "source": [
    "### Install `accelerate` (required for HuggingFace Trainer)\n",
    "\n",
    "HuggingFace `Trainer` relies on the **accelerate** library for efficient device\n",
    "management (CPU/GPU/MPS), mixed precision, and distributed training support.\n",
    "Even if training is done on CPU/MPS (MacBook Air), installing this package is\n",
    "recommended to avoid runtime warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f01b4bb8-052c-4c23-b165-f3b869c026ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/anaconda3/lib/python3.13/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2025.3.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cd91a-373b-4ffd-b950-08b5aed3b6a6",
   "metadata": {},
   "source": [
    "### 3) Define the RoBERTa model and evaluation metrics\n",
    "\n",
    "In this section we load a pretrained **RoBERTa-base** sequence classification\n",
    "model and attach a metric function that calculates accuracy, precision, recall,\n",
    "and F1 during validation.  \n",
    "The model is configured for **binary classification** with `num_labels=2`\n",
    "(stigmatizing = 0, supportive = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0fe71b1d-e4a2-44f8-8a2e-89f727c6f431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../roberta_stigma\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    do_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cf3c8-243a-4600-a044-71aed64abe58",
   "metadata": {},
   "source": [
    "### 4) Initialize the HuggingFace Trainer and start fine-tuning\n",
    "\n",
    "With the model, datasets, and training arguments prepared, we now create a\n",
    "`Trainer` object.  \n",
    "The Trainer API handles batching, optimization, evaluation, and metric logging\n",
    "automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "595501f3-a1fb-4a0c-a384-e0ed1fc6c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='152' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [152/152 01:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.368500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=152, training_loss=0.4787051501242738, metrics={'train_runtime': 64.2239, 'train_samples_per_second': 18.685, 'train_steps_per_second': 2.367, 'total_flos': 78933316608000.0, 'train_loss': 0.4787051501242738, 'epoch': 4.0})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf95a6f-b28c-4005-9258-6fcfe2f9d2a2",
   "metadata": {},
   "source": [
    "### 5) Evaluate the fine-tuned model on the test set\n",
    "\n",
    "After training and validation, we run the model on the held-out **test dataset**.\n",
    "The Trainer returns raw logits, which we convert to predicted class labels\n",
    "(using `argmax` for binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9fd2943e-e25f-4b41-b31c-23dfa6e42547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.50      0.62        26\n",
      "         1.0       0.83      0.96      0.89        68\n",
      "\n",
      "    accuracy                           0.83        94\n",
      "   macro avg       0.82      0.73      0.75        94\n",
      "weighted avg       0.83      0.83      0.82        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)\n",
    "\n",
    "test_df_eval = test_df.copy()\n",
    "test_df_eval[\"pred\"] = preds.predictions.argmax(axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_df_eval[\"label\"], test_df_eval[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d1a94174-4bcb-425f-a448-c83aa16ea15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2020</td>\n",
       "      <td>No, none of my previous supervisors No, at non...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2019</td>\n",
       "      <td>be forward solution focused instead of punitiv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2017</td>\n",
       "      <td>Just communicate it. It's a big problem and pe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2017</td>\n",
       "      <td>being more open about privacy and clear about ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2023</td>\n",
       "      <td>They actually brought the subject up based on ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                                               text  label    id  \\\n",
       "427  2020  No, none of my previous supervisors No, at non...    0.0  3167   \n",
       "90   2019  be forward solution focused instead of punitiv...    1.0  3003   \n",
       "233  2017  Just communicate it. It's a big problem and pe...    1.0  1741   \n",
       "364  2017  being more open about privacy and clear about ...    0.0  2166   \n",
       "65   2023  They actually brought the subject up based on ...    1.0    65   \n",
       "\n",
       "     pred  \n",
       "427     0  \n",
       "90      1  \n",
       "233     1  \n",
       "364     1  \n",
       "65      1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a079032-6686-4e31-bfcf-1205022a1bb1",
   "metadata": {},
   "source": [
    "### 6) Save the fine-tuned model and tokenizer\n",
    "\n",
    "After training and evaluation, we save both the model weights and the tokenizer\n",
    "so the classifier can be reloaded later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "107ff27e-ca50-4340-8c6f-f7219a8d523f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/roberta_stigma_v1/tokenizer_config.json',\n",
       " '../models/roberta_stigma_v1/special_tokens_map.json',\n",
       " '../models/roberta_stigma_v1/vocab.json',\n",
       " '../models/roberta_stigma_v1/merges.txt',\n",
       " '../models/roberta_stigma_v1/added_tokens.json',\n",
       " '../models/roberta_stigma_v1/tokenizer.json')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/roberta_stigma_v1\")\n",
    "tokenizer.save_pretrained(\"../models/roberta_stigma_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157242d5-908b-4e00-9941-6db0aa5a6495",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "### 1) Load the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5316988f-23cb-4b8b-9937-ba85ec20e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"../data/processed/full_text_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0523f5-1988-4d05-902a-598316dc6988",
   "metadata": {},
   "source": [
    "### Use GPU (MPS on Mac) of available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20a3f4cb-0aa0-419a-9223-062de3d8d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08a9b4d1-540f-4e56-841c-848a437e2386",
   "metadata": {},
   "source": [
    "## Create Inference Dataset class\n",
    "\n",
    "When running inference on the full dataset, we do not have labels –  \n",
    "we only need tokenized text to feed into the model.  \n",
    "The class below mirrors the training dataset but removes the label component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cc19b738-0a2d-44a5-b0b2-b7f7a6556a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d66ebcf-b7c8-44fc-a5dc-02720010642f",
   "metadata": {},
   "source": [
    "## Prepare dataloader\n",
    "\n",
    "To run inference efficiently, we batch the inputs using a PyTorch `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "90c9391a-6729-4706-a338-0e569147fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "523ea5f1-f187-4bea-badb-9bc2c392e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_full[\"text\"].astype(str).tolist()\n",
    "dataset = InferenceDataset(texts, tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf99d78-d074-4b38-8732-a2a1b61068d3",
   "metadata": {},
   "source": [
    "## Run inference\n",
    "\n",
    "We now pass the full dataset through the fine-tuned RoBERTa model in batches.  \n",
    "Gradient tracking is disabled to speed up inference and reduce memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "201c79b5-7b51-41cd-8c36-c54970b1e327",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        batch_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "        preds.extend(batch_preds)\n",
    "\n",
    "df_full[\"stigma_pred\"] = preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58355b41-9006-45d1-94f3-35eeb4cff6ab",
   "metadata": {},
   "source": [
    "### Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "98857cae-6309-417d-a900-559d25305728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>stigma_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>I'm not on my company's health insurance, whic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>I have chronic, low-level neurological issues ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>My company does provide healthcare, but not to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>Relatively new job. Ask again later</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Sometimes I think  about using drugs for my me...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                               text  label  stigma_pred\n",
       "0  2014  I'm not on my company's health insurance, whic...    NaN            0\n",
       "1  2014  I have chronic, low-level neurological issues ...    NaN            1\n",
       "2  2014  My company does provide healthcare, but not to...    NaN            0\n",
       "3  2014                Relatively new job. Ask again later    NaN            1\n",
       "4  2014  Sometimes I think  about using drugs for my me...    NaN            1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.to_csv(\"../data/processed/full_with_predictions.csv\", index=False)\n",
    "\n",
    "# Preview the saved dataframe\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0dd02-f21f-47bc-abae-edba9d2a82ab",
   "metadata": {},
   "source": [
    "### Trend analysis by year\n",
    "\n",
    "We now examine how the predicted attitudes toward mental health evolve over time.  \n",
    "Because the model outputs **1 = supportive** and **0 = stigmatizing**, the yearly mean of `stigma_pred`\n",
    "directly represents the share of **supportive** responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8ced9182-b80c-45e8-8071-64e34f4fa47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trend over years:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>share_supportive</th>\n",
       "      <th>share_stigmatizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.055215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.749477</td>\n",
       "      <td>0.250523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.832642</td>\n",
       "      <td>0.167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.838806</td>\n",
       "      <td>0.161194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.660920</td>\n",
       "      <td>0.339080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  share_supportive  share_stigmatizing\n",
       "0  2014          0.944785            0.055215\n",
       "1  2016          0.749477            0.250523\n",
       "2  2017          0.832642            0.167358\n",
       "3  2018          0.870000            0.130000\n",
       "4  2019          0.838806            0.161194\n",
       "5  2020          0.660920            0.339080\n",
       "6  2021          0.689655            0.310345\n",
       "7  2022          0.641026            0.358974\n",
       "8  2023          0.833333            0.166667"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend = (\n",
    "    df_full.groupby(\"year\")[\"stigma_pred\"]\n",
    "    .mean()  # mean = % supportive (label 1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"stigma_pred\": \"share_supportive\"})\n",
    ")\n",
    "\n",
    "trend[\"share_stigmatizing\"] = 1 - trend[\"share_supportive\"]\n",
    "\n",
    "print(\"\\nTrend over years:\")\n",
    "trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12cc9a-91bd-4a73-9d62-ba750631277e",
   "metadata": {},
   "source": [
    "### Plotting Yearly Trends in Mental-Health Attitudes\n",
    "\n",
    "To visualize how supportive vs. stigmatizing attitudes have changed over time,  \n",
    "we plot the yearly proportions computed in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3b590e4-f98d-43cd-bfdd-ae23792d6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(trend[\"year\"], trend[\"share_stigmatizing\"], marker=\"o\", label=\"Stigmatizing %\")\n",
    "plt.plot(trend[\"year\"], trend[\"share_supportive\"], marker=\"o\", label=\"Supportive %\")\n",
    "\n",
    "plt.title(\"Attitudes Toward Mental Health Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4cd2a-6fe2-4399-9072-8fd604b8eefd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
